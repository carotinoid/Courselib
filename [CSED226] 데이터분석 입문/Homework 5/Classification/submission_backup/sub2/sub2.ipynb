{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "You can use any models or methods you have learned in class (Decision Tree, Ensembles, SVM, etc.) *except kNN   \n",
    "In the classification task, we will use Weighted F1 score for the evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Versions\n",
    "> 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]   \n",
    "> numpy: 2.1.0   \n",
    "> pandas: 2.2.2   \n",
    "> matplotlib.pyplot: 3.9.2   \n",
    "> sklearn: 1.5.2   \n",
    "> scipy: 1.14.1   \n",
    "> seaborn: 0.13.2   \n",
    "> xgboost: 2.1.2   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "from importlib import reload\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(sys.modules['settings'])\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG:\n",
    "    log_file = open(LOG_FILE, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSV data, Preprocessing #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GP', 'GS', 'MIN']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv(DATA_PATH + \"\\\\train.csv\")\n",
    "testing_data = pd.read_csv(DATA_PATH + \"\\\\test.csv\")\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "training_data[\"position\"] = label_encoder.fit_transform(training_data[\"position\"])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_col = []\n",
    "for col in training_data.columns:\n",
    "    if col not in testing_data.columns:\n",
    "        drop_col.append(col)\n",
    "drop_col.remove(\"position\")\n",
    "training_data.drop(columns=drop_col, inplace=True)\n",
    "training_data.drop(columns=[\"SEASON_ID\", \"TEAM_ID\"], inplace=True)\n",
    "testing_data.drop(columns=[\"ID\", \"SEASON_ID\", \"TEAM_ID\"], inplace=True)\n",
    "\n",
    "# Process missing values\n",
    "if METHOD_PROCESSING_MISSING_VALUES == \"drop\":\n",
    "    training_data.dropna(inplace=True)\n",
    "elif METHOD_PROCESSING_MISSING_VALUES == \"mean\":\n",
    "    training_data.fillna(training_data.mean(), inplace=True)\n",
    "elif METHOD_PROCESSING_MISSING_VALUES == \"med\":\n",
    "    training_data.fillna(training_data.median(), inplace=True)\n",
    "elif METHOD_PROCESSING_MISSING_VALUES == \"mode\":\n",
    "    training_data.fillna(training_data.mode(), inplace=True)\n",
    "else:\n",
    "    raise(\"Invalid method for processing missing values\")\n",
    "\n",
    "# Divide data into X and y\n",
    "X = training_data.drop(columns=[\"position\"])\n",
    "y = training_data[\"position\"]\n",
    "\n",
    "# Feature scaling\n",
    "if SCALER == None:\n",
    "    pass\n",
    "elif SCALER == \"std\":\n",
    "    scaler = StandardScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    testing_data = pd.DataFrame(scaler.transform(testing_data), columns=testing_data.columns)\n",
    "elif SCALER == \"minmax\":\n",
    "    scaler = MinMaxScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    testing_data = pd.DataFrame(scaler.transform(testing_data), columns=testing_data.columns)\n",
    "else:\n",
    "    raise(\"Invalid scaler\")\n",
    "\n",
    "# TSNE or PCA\n",
    "if ADD_TSNE[0] == True:\n",
    "    tsne = TSNE(n_components=ADD_TSNE[1])\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "    X = pd.concat([X, pd.DataFrame(X_tsne)], axis=1)\n",
    "if ADD_PCA[0] == True:\n",
    "    pca = PCA(n_components=ADD_PCA[1])\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X = pd.concat([X, pd.DataFrame(X_pca)], axis=1)\n",
    "\n",
    "# Info. of data\n",
    "print(drop_col)\n",
    "print(len(X.columns))\n",
    "training_data\n",
    "\n",
    "# logging\n",
    "if LOG:\n",
    "    try: \n",
    "        log_file.write(\"Number of columns: \" + str(len(X.columns)) + \"\\n\")\n",
    "        log_file.write(\"Number of rows: \" + str(len(X)) + \"\\n\")\n",
    "        log_file.write(\"Columns: \")\n",
    "        for col in X.columns:\n",
    "            log_file.write(col + \" \")\n",
    "        log_file.write(\"\\n\")\n",
    "    except IOError:\n",
    "        print(\"logger is not working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA (Heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output image was saved as \"Corr_heatmap.png\" in WORKSPACE folder.\n",
    "\n",
    "# plt.figure(figsize=(15,15))\n",
    "# figure = sns.heatmap(training_data.corr(), annot=True, fmt=\".2f\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: PLAYER_AGE, FGA, FG_PCT, FG3A, FTA, FT_PCT, OREB, DREB, REB, AST, STL, BLK, PF, PTS, \n"
     ]
    }
   ],
   "source": [
    "# Remove unrelated feature using RFE.\n",
    "if 0 > NUM_SELECTED_FEATURES or NUM_SELECTED_FEATURES > len(X.columns):\n",
    "    raise(\"Invalid number of selected features\")\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=NUM_SELECTED_FEATURES)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "print(\"Selected features: \", end=\"\")\n",
    "for i in range(X.shape[1]):\n",
    "    if rfe.support_[i]:\n",
    "        print(X.columns[i], end=\", \")\n",
    "print()\n",
    "\n",
    "X_selected = rfe.transform(X)\n",
    "testing_data_selected = rfe.transform(testing_data)\n",
    "\n",
    "# Logging\n",
    "if LOG:\n",
    "    try:\n",
    "        log_file.write(\"Number of selected features: \" + str(NUM_SELECTED_FEATURES) + \"\\n\")\n",
    "        log_file.write(\"Selected features: \")\n",
    "        for i in range(X.shape[1]):\n",
    "            if rfe.support_[i]:\n",
    "                log_file.write(X.columns[i] + \", \")\n",
    "        log_file.write(\"\\n\")\n",
    "    except IOError:\n",
    "        print(\"logger is not working\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "2 fits failed out of a total of 2025.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1512, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1003, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 1573, in __init__\n",
      "    self._init(\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 1632, in _init\n",
      "    it.reraise()\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 569, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 550, in _handle_exception\n",
      "    return fn()\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 637, in <lambda>\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py\", line 1388, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 626, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 954, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 1092, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py\", line 1334, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py\", line 679, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py\", line 1267, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:20:01] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\data\\array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 46) : \n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan 0.64231909        nan 0.6406459  0.64014423 0.64173373\n",
      " 0.64190131 0.63997683 0.64173366 0.63780089 0.6402277  0.64148248\n",
      " 0.63830295 0.63989283 0.63880521 0.63830347 0.63972501 0.64240284\n",
      " 0.63495637 0.63863785 0.64298823 0.63478823 0.63964126 0.6405619\n",
      " 0.63612833 0.63370082 0.64014321 0.64056302 0.64022809 0.64056229\n",
      " 0.64491347 0.64164981 0.64014381 0.64081341 0.64098056 0.64139911\n",
      " 0.64114775 0.64039458 0.63922331 0.63897212 0.64056229 0.6406459\n",
      " 0.63972522 0.641399   0.64072979 0.63713206 0.64022728 0.64223576\n",
      " 0.63688088 0.63888868 0.63939116 0.63872192 0.64148223 0.63989322\n",
      " 0.63964238 0.64114827 0.63847013 0.63939116 0.64114806 0.63888851\n",
      " 0.64340741 0.64014433 0.63964196 0.64039489 0.64190113 0.63771658\n",
      " 0.64290462 0.63830358 0.63796808 0.63922411 0.64148248 0.63763384\n",
      " 0.63997648 0.64148272 0.64123126 0.63989273 0.64123154 0.64056197\n",
      " 0.63830323 0.64123164 0.63922415 0.63964242 0.64215204 0.63847059\n",
      " 0.6399768  0.64215225 0.63788464 0.63922327 0.64031149 0.63738262\n",
      " 0.63838712 0.6376337  0.63780061 0.64064632 0.63755016 0.63754974\n",
      " 0.63746637 0.64031117 0.63796853 0.64081348 0.63813558 0.64031138\n",
      " 0.63629489 0.63888921 0.63838698 0.63980821 0.6403944  0.63763363\n",
      " 0.63412    0.63863771 0.63102426 0.63470574 0.63696442 0.63336634\n",
      " 0.63345065 0.63746644 0.63252983 0.636211   0.63462178 0.63554207\n",
      " 0.63529099 0.6367967  0.63428712 0.63570887 0.63420305 0.63503949\n",
      " 0.6339519  0.63587701 0.63370145 0.63386822 0.63621149 0.63771714\n",
      " 0.6361277  0.63520766 0.63579301 0.64190057 0.63939036 0.63997638\n",
      " 0.63939046 0.63997683 0.6393905  0.64056271 0.63980943 0.63897226\n",
      " 0.64047784 0.63838652 0.64089667 0.63997704 0.64005971 0.64273739\n",
      " 0.6370473  0.63738251 0.64014388 0.63453796 0.63646198 0.64064583\n",
      " 0.63688035 0.64056159 0.63997599 0.63503942 0.6379685  0.64031072\n",
      " 0.6417331  0.64056239 0.63880511 0.64056253 0.64047875 0.63796825\n",
      " 0.64164988 0.63863851 0.63763363 0.63855385 0.6432399  0.63763415\n",
      " 0.64106428 0.63880521 0.63838659 0.64198432 0.63997652 0.63939095\n",
      " 0.63604388 0.64114764 0.63888858 0.64089649 0.63821888 0.63830295\n",
      " 0.63838635 0.63880458 0.63855347 0.64089642 0.64123161 0.63821937\n",
      " 0.63972592 0.64215155 0.63855389 0.64031135 0.63972575 0.63796801\n",
      " 0.6399762  0.63813527 0.63788447 0.63905608 0.6386376  0.63629528\n",
      " 0.63612763 0.63847031 0.63763384 0.63913991 0.64131536 0.63872129\n",
      " 0.64340632 0.63980891 0.63880483 0.6417331  0.63729946 0.63738234\n",
      " 0.63939067 0.63671362 0.63780103 0.64089695 0.63771759 0.63763366\n",
      " 0.63997634 0.63780092 0.63746592 0.64365814 0.63512383 0.63738335\n",
      " 0.63855417 0.63679709 0.63545839 0.63763363 0.63838659 0.63579291\n",
      " 0.63863764 0.6397255  0.63688014 0.63763391 0.63596069 0.63805193\n",
      " 0.63805183 0.63729908 0.63813537 0.63537485 0.63411979 0.63052153\n",
      " 0.63654597 0.63378534 0.63286386 0.63554252 0.63512348 0.63344988\n",
      " 0.63554182 0.63378541 0.62985257 0.63453813 0.63236278 0.63160957\n",
      " 0.63512352 0.63169361 0.63261337 0.63512345 0.63537439 0.63487251\n",
      " 0.63487212 0.63378457 0.635542   0.63428726 0.63395246 0.63361763\n",
      " 0.64014342 0.64089639 0.64006072 0.63696393 0.6393906  0.6414823\n",
      " 0.63654611 0.6402276  0.63679726 0.63947414 0.63847052 0.64081316\n",
      " 0.63880507 0.63930674 0.63704824 0.63788433 0.63980877 0.638052\n",
      " 0.63637861 0.64081243 0.63947428 0.63913952 0.63562568 0.63964161\n",
      " 0.6320275  0.6378844  0.63897258 0.64148269 0.64031089 0.63997715\n",
      " 0.64123168 0.6408133  0.63729936 0.63980989 0.64006009 0.63570947\n",
      " 0.64072923 0.63838659 0.63470539 0.64097954 0.6398929  0.63679747\n",
      " 0.63654545 0.64173352 0.64039503 0.64022749 0.63788478 0.63796899\n",
      " 0.63855375 0.64399294 0.6379686  0.63629458 0.64198478 0.63596097\n",
      " 0.63980943 0.63847034 0.63520755 0.64106393 0.64072948 0.63621163\n",
      " 0.63930734 0.63997599 0.63453782 0.64164974 0.63939081 0.63671355\n",
      " 0.63863736 0.63997652 0.63462199 0.63947463 0.64257013 0.63587676\n",
      " 0.63880556 0.63863813 0.63604437 0.6398094  0.6411482  0.63805207\n",
      " 0.63738279 0.6402276  0.63654643 0.6403951  0.64022767 0.63587725\n",
      " 0.64173352 0.63780117 0.63637913 0.64014356 0.63980894 0.63621177\n",
      " 0.63863778 0.63813569 0.63537509 0.63821923 0.63955888 0.63587701\n",
      " 0.63922366 0.64006013 0.63478956 0.6408967  0.64173373 0.63587645\n",
      " 0.64047871 0.63788538 0.63596006 0.63520748 0.63872192 0.63696466\n",
      " 0.63453806 0.63361791 0.63052223 0.63529102 0.63428691 0.63227882\n",
      " 0.63562579 0.63445452 0.63135867 0.63420368 0.63503991 0.63202816\n",
      " 0.63269783 0.6349564  0.63186066 0.63412025 0.63453771 0.63102426\n",
      " 0.6334503  0.63529109 0.6325298  0.63437101 0.63286481 0.63420333\n",
      " 0.63420316 0.63504068 0.63328311]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6, 'gamma': 1, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6}\n",
      "0.6449134743432922\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "# params = {\n",
    "#     # eta, num_boost_around, min_child_weight, max_depth, gamma, sub_sample, colsample_bytree, lambda, alpha, scale_pos_weight\n",
    "#     \"max_depth\": [3, 5, 7, 9, 11],\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "# Note: https://www.kaggle.com/code/tilii7/hyperparameter-grid-search-with-xgboost\n",
    "\n",
    "if LOG:\n",
    "    try:\n",
    "        log_file.write(\"Model: \" + str(type(model)) + \"\\n\")\n",
    "    except IOError:\n",
    "        print(\"logger is not working\")\n",
    "\n",
    "# Validation (Not implemented)\n",
    "if METHOD_VALIDATION == \"kf\":\n",
    "    grid = GridSearchCV(estimator=model, param_grid=params, cv=kf, n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_selected, y)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    if LOG:\n",
    "        try:\n",
    "            log_file.write(\"Best parameters: \" + str(grid.best_params_) + \"\\n\")\n",
    "            log_file.write(\"Best score: \" + str(grid.best_score_) + \"\\n\")\n",
    "        except IOError:\n",
    "            print(\"logger is not working\")\n",
    "\n",
    "\n",
    "elif METHOD_VALIDATION == \"skf\":\n",
    "    grid = GridSearchCV(estimator=model, param_grid=params, cv=skf, n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_selected, y)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    if LOG:\n",
    "        try:\n",
    "            log_file.write(\"Best parameters: \" + str(grid.best_params_) + \"\\n\")\n",
    "            log_file.write(\"Best score: \" + str(grid.best_score_) + \"\\n\")\n",
    "        except IOError:\n",
    "            print(\"logger is not working\")\n",
    "\n",
    "\n",
    "elif METHOD_VALIDATION == None:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    print(f1_score(y_val, y_pred, average=\"weighted\"))\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    if LOG:\n",
    "        try:\n",
    "            log_file.write(\"F1 score: \" + str(f1_score(y_val, y_pred, average=\"weighted\")) + \"\\n\")\n",
    "            log_file.write(\"Classification report: \\n\" + classification_report(y_val, y_pred) + \"\\n\")\n",
    "        except IOError:\n",
    "            print(\"logger is not working\")\n",
    "\n",
    "\n",
    "else:\n",
    "    raise(\"Invalid method for validation\")\n",
    "\n",
    "\n",
    "print(type(model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training new model with selected model, hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID position\n",
      "0        1  Forward\n",
      "1        2    Guard\n",
      "2        3    Guard\n",
      "3        4   Center\n",
      "4        5   Center\n",
      "...    ...      ...\n",
      "1995  1996    Guard\n",
      "1996  1997    Guard\n",
      "1997  1998  Forward\n",
      "1998  1999   Center\n",
      "1999  2000    Guard\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def for_submission():\n",
    "    model = XGBClassifier(colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6)\n",
    "    model.fit(X_selected, y)\n",
    "\n",
    "    y_pred = model.predict(testing_data_selected)\n",
    "\n",
    "    submission_df = pd.DataFrame()\n",
    "    temp = pd.read_csv(DATA_PATH + \"\\\\test.csv\")\n",
    "    submission_df[\"ID\"] = temp[\"ID\"]\n",
    "    \n",
    "    submission_df[\"position\"] = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    print(submission_df)\n",
    "    submission_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "for_submission()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Close log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    log_file.close()\n",
    "except IOError:\n",
    "    print(\"logger is not working\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
