{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "You can use any models or methods you have learned in class (Decision Tree, Ensembles, SVM, etc.) *except kNN   \n",
    "In the regression task, MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Versions\n",
    "> 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]   \n",
    "> numpy: 2.1.0   \n",
    "> pandas: 2.2.2   \n",
    "> matplotlib.pyplot: 3.9.2   \n",
    "> sklearn: 1.5.2   \n",
    "> scipy: 1.14.1   \n",
    "> seaborn: 0.13.2   \n",
    "> xgboost: 2.1.2   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier,XGBRFClassifier, XGBRegressor, XGBRFRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "from importlib import reload\n",
    "from pactools.grid_search import GridSearchCVProgressBar\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Workspace\\Dataanalysis_homework_5\\Regression\\settings.py:2: DeprecationWarning: invalid escape sequence '\\W'\n",
      "  WORKSPACE = \"D:\\Workspace\\Dataanalysis_homework_5\\Regression\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'settings' from 'd:\\\\Workspace\\\\Dataanalysis_homework_5\\\\Regression\\\\settings.py'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from settings import *\n",
    "reload(sys.modules['settings'])\n",
    "from settings import *\n",
    "reload(sys.modules['settings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carot\\AppData\\Local\\Temp\\ipykernel_24356\\3002299574.py:2: ResourceWarning: unclosed file <_io.TextIOWrapper name='D:\\\\Workspace\\\\Dataanalysis_homework_5\\\\Regression\\\\log.txt' mode='w' encoding='cp949'>\n",
      "  log_file = open(LOG_FILE, 'w')\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "if LOG:\n",
    "    log_file = open(LOG_FILE, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['position']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv(DATA_PATH + \"\\\\train.csv\")\n",
    "testing_data = pd.read_csv(DATA_PATH + \"\\\\test.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_col = []\n",
    "for col in training_data.columns:\n",
    "    if col not in testing_data.columns:\n",
    "        drop_col.append(col)\n",
    "drop_col.remove(\"MIN\")\n",
    "training_data.drop(columns=drop_col, inplace=True)\n",
    "training_data.drop(columns=[\"SEASON_ID\", \"TEAM_ID\"], inplace=True)\n",
    "testing_data.drop(columns=[\"ID\", \"SEASON_ID\", \"TEAM_ID\"], inplace=True)\n",
    "\n",
    "# Process missing values\n",
    "if METHOD_PROCESSING_MISSING_VALUES == \"drop\":\n",
    "    training_data.dropna(inplace=True)\n",
    "elif METHOD_PROCESSING_MISSING_VALUES == \"mean\":\n",
    "    training_data.fillna(training_data.mean(), inplace=True)\n",
    "elif METHOD_PROCESSING_MISSING_VALUES == \"med\":\n",
    "    training_data.fillna(training_data.median(), inplace=True)\n",
    "elif METHOD_PROCESSING_MISSING_VALUES == \"mode\":\n",
    "    training_data.fillna(training_data.mode(), inplace=True)\n",
    "else:\n",
    "    raise(\"Invalid method for processing missing values\")\n",
    "\n",
    "# Divide data into X and y\n",
    "X = training_data.drop(columns=[\"MIN\"])\n",
    "y = training_data[\"MIN\"]\n",
    "\n",
    "# Feature scaling\n",
    "if SCALER == None:\n",
    "    pass\n",
    "elif SCALER == \"std\":\n",
    "    scaler = StandardScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    testing_data = pd.DataFrame(scaler.transform(testing_data), columns=testing_data.columns)\n",
    "elif SCALER == \"minmax\":\n",
    "    scaler = MinMaxScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    testing_data = pd.DataFrame(scaler.transform(testing_data), columns=testing_data.columns)\n",
    "else:\n",
    "    raise(\"Invalid scaler\")\n",
    "\n",
    "if LOG:\n",
    "    try:\n",
    "        log_file.write(\"Scaler: \" + str(scaler) + \"\\n\")\n",
    "    except IOError:\n",
    "        print(\"logger is not working\")\n",
    "\n",
    "# TSNE or PCA\n",
    "if ADD_TSNE[0] == True:\n",
    "    tsne = TSNE(n_components=ADD_TSNE[1])\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "    X = pd.concat([X, pd.DataFrame(X_tsne)], axis=1)\n",
    "if ADD_PCA[0] == True:\n",
    "    pca = PCA(n_components=ADD_PCA[1])\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X = pd.concat([X, pd.DataFrame(X_pca)], axis=1)\n",
    "\n",
    "# Info. of data\n",
    "print(drop_col)\n",
    "print(len(X.columns))\n",
    "training_data\n",
    "\n",
    "# logging\n",
    "if LOG:\n",
    "    try: \n",
    "        log_file.write(\"Number of columns: \" + str(len(X.columns)) + \"\\n\")\n",
    "        log_file.write(\"Number of rows: \" + str(len(X)) + \"\\n\")\n",
    "        log_file.write(\"Columns: \")\n",
    "        for col in X.columns:\n",
    "            log_file.write(str(col) + \" \")\n",
    "        log_file.write(\"\\n\")\n",
    "    except IOError:\n",
    "        print(\"logger is not working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: PLAYER_AGE, FGA, FG_PCT, FTM, FTA, FT_PCT, OREB, REB, AST, STL, BLK, TOV, PF, PTS, \n"
     ]
    }
   ],
   "source": [
    "# Remove unrelated feature using RFE.\n",
    "if 0 > NUM_SELECTED_FEATURES or NUM_SELECTED_FEATURES > len(X.columns):\n",
    "    raise(\"Invalid number of selected features\")\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=NUM_SELECTED_FEATURES)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "print(\"Selected features: \", end=\"\")\n",
    "for i in range(X.shape[1]):\n",
    "    if rfe.support_[i]:\n",
    "        print(X.columns[i], end=\", \")\n",
    "print()\n",
    "\n",
    "X_selected = rfe.transform(X)\n",
    "# testing_data_selected = rfe.transform(testing_data)\n",
    "testing_data_selected = testing_data[X.columns[rfe.support_]]\n",
    "\n",
    "# Logging\n",
    "if LOG:\n",
    "    try:\n",
    "        log_file.write(\"Number of selected features: \" + str(NUM_SELECTED_FEATURES) + \"\\n\")\n",
    "        log_file.write(\"Selected features: \")\n",
    "        for i in range(X.shape[1]):\n",
    "            if rfe.support_[i]:\n",
    "                log_file.write(X.columns[i] + \", \")\n",
    "        log_file.write(\"\\n\")\n",
    "    except IOError:\n",
    "        print(\"logger is not working\")\n",
    "\n",
    "# Selected features: PLAYER_AGE, FGM, FGA, FG_PCT, FTM, FTA, FT_PCT, OREB, REB, AST, STL, TOV, PF, PTS, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
      "-30753.01228983947\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "params = None\n",
    "if METHOD_MODEL == \"xgb\":\n",
    "    model = XGBRegressor()\n",
    "    params = XGBOOST_PARAMS\n",
    "elif METHOD_MODEL == \"rf\":\n",
    "    model = RandomForestRegressor()\n",
    "    params = RANDOM_FOREST_PARAMS\n",
    "elif METHOD_MODEL == \"svc\":\n",
    "    model = SVC()\n",
    "    params = SVC_PARAMS\n",
    "elif METHOD_MODEL == 'xgbrf':\n",
    "    model = XGBRFRegressor()\n",
    "    params = XGBOOST_PARAMS\n",
    "else:\n",
    "    raise(\"Invalid model\")\n",
    "\n",
    "if LOG:\n",
    "    try:\n",
    "        log_file.write(\"Model: \" + METHOD_MODEL + \"\\n\")\n",
    "        log_file.write(\"Validation: \" + METHOD_VALIDATION + \"\\n\")\n",
    "        log_file.write(\"Search: \" + METHOD_SEARCH + \"\\n\")\n",
    "        log_file.write(\"Parameters: \" + str(params) + \"\\n\")\n",
    "    except IOError:\n",
    "        print(\"logger is not working\")\n",
    "\n",
    "if METHOD_VALIDATION == \"kf\":\n",
    "    if METHOD_SEARCH == \"grid\":\n",
    "        grid = GridSearchCVProgressBar(estimator=model, param_grid=params, cv=kf, n_jobs=-1, verbose=10, scoring=\"neg_mean_squared_error\")\n",
    "    elif METHOD_SEARCH == \"random\":\n",
    "        grid = RandomizedSearchCV(estimator=model, param_distributions=params, cv=kf, n_jobs=-1, verbose=10, scoring=\"neg_mean_squared_error\")\n",
    "    else:\n",
    "        raise(\"Invalid method for search\")\n",
    "    grid.fit(X_selected, y)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    if LOG:\n",
    "        try:\n",
    "            log_file.write(\"Best parameters: \" + str(grid.best_params_) + \"\\n\")\n",
    "            log_file.write(\"Best score: \" + str(grid.best_score_) + \"\\n\")\n",
    "        except IOError:\n",
    "            print(\"logger is not working\")\n",
    "\n",
    "\n",
    "elif METHOD_VALIDATION == \"skf\":\n",
    "    if METHOD_SEARCH == \"grid\":\n",
    "        grid = GridSearchCV(estimator=model, param_grid=params, cv=skf, n_jobs=-1, verbose=10, scoring=\"neg_mean_squared_error\")\n",
    "    elif METHOD_SEARCH == \"random\":\n",
    "        grid = RandomizedSearchCV(estimator=model, param_distributions=params, cv=skf, n_jobs=-1, verbose=10, scoring=\"neg_mean_squared_error\")\n",
    "    else:\n",
    "        raise(\"Invalid method for search\")\n",
    "    grid.fit(X_selected, y)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    if LOG:\n",
    "        try:\n",
    "            log_file.write(\"Best parameters: \" + str(grid.best_params_) + \"\\n\")\n",
    "            log_file.write(\"Best score: \" + str(grid.best_score_) + \"\\n\")\n",
    "        except IOError:\n",
    "            print(\"logger is not working\")\n",
    "\n",
    "elif METHOD_VALIDATION == None:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    # MSE\n",
    "    print(np.sqrt(np.mean((y_pred - y_val) ** 2)))\n",
    "    if LOG:\n",
    "        try:\n",
    "            log_file.write(\"MSE: \" + str(np.sqrt(np.mean((y_pred - y_val) ** 2))) + \"\\n\")\n",
    "        except IOError:\n",
    "            print(\"logger is not working\")\n",
    "\n",
    "\n",
    "else:\n",
    "    raise(\"Invalid method for validation\")\n",
    "\n",
    "best_model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID        MIN\n",
      "0        1    42.2725\n",
      "1        2  2355.9725\n",
      "2        3  1646.2925\n",
      "3        4   451.5825\n",
      "4        5   129.4050\n",
      "...    ...        ...\n",
      "1995  1996  2525.1150\n",
      "1996  1997  1118.0350\n",
      "1997  1998  1007.0100\n",
      "1998  1999  1089.7775\n",
      "1999  2000   381.6375\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "model = best_model\n",
    "y_pred = model.predict(testing_data_selected)\n",
    "submission_df = pd.DataFrame()\n",
    "temp = pd.read_csv(DATA_PATH + \"\\\\test.csv\")\n",
    "submission_df[\"ID\"] = temp[\"ID\"]\n",
    "submission_df[\"MIN\"] = y_pred\n",
    "print(submission_df)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Close log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    log_file.close()\n",
    "except IOError:\n",
    "    print(\"logger is not working\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
