{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "You can use any models or methods you have learned in class (Decision Tree, Ensembles, SVM, etc.) *except kNN   \n",
    "In the regression task, MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Versions\n",
    "> 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]   \n",
    "> numpy: 2.1.0   \n",
    "> pandas: 2.2.2   \n",
    "> matplotlib.pyplot: 3.9.2   \n",
    "> sklearn: 1.5.2   \n",
    "> scipy: 1.14.1   \n",
    "> seaborn: 0.13.2   \n",
    "> xgboost: 2.1.2   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier,XGBRFClassifier, XGBRegressor, XGBRFRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "from importlib import reload\n",
    "from pactools.grid_search import GridSearchCVProgressBar\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'settings' from 'd:\\\\Workspace\\\\Dataanalysis_homework_5\\\\Regression\\\\settings.py'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from settings import *\n",
    "reload(sys.modules['settings'])\n",
    "from settings import *\n",
    "reload(sys.modules['settings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    log_file.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if LOG:\n",
    "    log_file = open(LOG_FILE, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['position']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv(DATA_PATH + \"\\\\train.csv\")\n",
    "testing_data = pd.read_csv(DATA_PATH + \"\\\\test.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_col = []\n",
    "for col in training_data.columns:\n",
    "    if col not in testing_data.columns:\n",
    "        drop_col.append(col)\n",
    "drop_col.remove(\"MIN\")\n",
    "training_data.drop(columns=drop_col, inplace=True)\n",
    "training_data.drop(columns=[\"SEASON_ID\", \"TEAM_ID\"], inplace=True)\n",
    "testing_data.drop(columns=[\"ID\", \"SEASON_ID\", \"TEAM_ID\"], inplace=True)\n",
    "\n",
    "# Process missing values\n",
    "if METHOD_PROCESSING_MISSING_VALUES == \"drop\":\n",
    "    training_data.dropna(inplace=True)\n",
    "elif METHOD_PROCESSING_MISSING_VALUES == \"mean\":\n",
    "    training_data.fillna(training_data.mean(), inplace=True)\n",
    "elif METHOD_PROCESSING_MISSING_VALUES == \"med\":\n",
    "    training_data.fillna(training_data.median(), inplace=True)\n",
    "elif METHOD_PROCESSING_MISSING_VALUES == \"mode\":\n",
    "    training_data = training_data[training_data[\"MIN\"].notna()]\n",
    "    training_data.fillna(training_data.mode(), inplace=True)\n",
    "else:\n",
    "    raise(\"Invalid method for processing missing values\")\n",
    "\n",
    "if LOG:\n",
    "    try:\n",
    "        log_file.write(\"Method for processing missing values: \" + METHOD_PROCESSING_MISSING_VALUES + \"\\n\")\n",
    "    except IOError:\n",
    "        print(\"logger is not working\")\n",
    "\n",
    "\n",
    "# Divide data into X and y\n",
    "X = training_data.drop(columns=[\"MIN\"])\n",
    "y = training_data[\"MIN\"]\n",
    "\n",
    "# Feature scaling\n",
    "if SCALER == None:\n",
    "    pass\n",
    "elif SCALER == \"std\":\n",
    "    scaler = StandardScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    testing_data = pd.DataFrame(scaler.transform(testing_data), columns=testing_data.columns)\n",
    "elif SCALER == \"minmax\":\n",
    "    scaler = MinMaxScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    testing_data = pd.DataFrame(scaler.transform(testing_data), columns=testing_data.columns)\n",
    "else:\n",
    "    raise(\"Invalid scaler\")\n",
    "\n",
    "if LOG:\n",
    "    try:\n",
    "        if(SCALER == None):\n",
    "            log_file.write(\"Scaler: None\\n\")\n",
    "        else:\n",
    "            log_file.write(\"Scaler: \" + str(scaler) + \"\\n\")\n",
    "    except IOError:\n",
    "        print(\"logger is not working\")\n",
    "\n",
    "# TSNE or PCA\n",
    "if ADD_TSNE[0] == True:\n",
    "    tsne = TSNE(n_components=ADD_TSNE[1])\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "    X = pd.concat([X, pd.DataFrame(X_tsne)], axis=1)\n",
    "if ADD_PCA[0] == True:\n",
    "    pca = PCA(n_components=ADD_PCA[1])\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X = pd.concat([X, pd.DataFrame(X_pca)], axis=1)\n",
    "\n",
    "# Info. of data\n",
    "print(drop_col)\n",
    "print(len(X.columns))\n",
    "training_data\n",
    "\n",
    "# logging\n",
    "if LOG:\n",
    "    try: \n",
    "        log_file.write(\"Number of columns: \" + str(len(X.columns)) + \"\\n\")\n",
    "        log_file.write(\"Number of rows: \" + str(len(X)) + \"\\n\")\n",
    "        log_file.write(\"Columns: \")\n",
    "        for col in X.columns:\n",
    "            log_file.write(str(col) + \" \")\n",
    "        log_file.write(\"\\n\")\n",
    "    except IOError:\n",
    "        print(\"logger is not working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove unrelated feature using RFE.\n",
    "# if 0 > NUM_SELECTED_FEATURES or NUM_SELECTED_FEATURES > len(X.columns):\n",
    "#     raise(\"Invalid number of selected features\")\n",
    "# rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=NUM_SELECTED_FEATURES)\n",
    "\n",
    "# rfe.fit(X, y)\n",
    "\n",
    "# print(\"Selected features: \", end=\"\")\n",
    "# for i in range(X.shape[1]):\n",
    "#     if rfe.support_[i]:\n",
    "#         print(X.columns[i], end=\", \")\n",
    "# print()\n",
    "\n",
    "# X_selected = rfe.transform(X)\n",
    "# # testing_data_selected = rfe.transform(testing_data)\n",
    "# testing_data_selected = testing_data[X.columns[rfe.support_]]\n",
    "\n",
    "# # Logging\n",
    "# if LOG:\n",
    "#     try:\n",
    "#         log_file.write(\"Number of selected features: \" + str(NUM_SELECTED_FEATURES) + \"\\n\")\n",
    "#         log_file.write(\"Selected features: \")\n",
    "#         for i in range(X.shape[1]):\n",
    "#             if rfe.support_[i]:\n",
    "#                 log_file.write(X.columns[i] + \", \")\n",
    "#         log_file.write(\"\\n\")\n",
    "#     except IOError:\n",
    "#         print(\"logger is not working\")\n",
    "\n",
    "X_selected = X\n",
    "\n",
    "# # Selected features: PLAYER_AGE, FGM, FGA, FG_PCT, FTM, FTA, FT_PCT, OREB, REB, AST, STL, TOV, PF, PTS, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "300 fits failed out of a total of 900.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "300 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\carot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [            nan             nan             nan             nan\n",
      " -28147.91324346 -27988.76311847 -28030.27917123 -27989.97010785\n",
      " -28229.83237943 -28112.24500473 -28101.89408812 -28116.59349973\n",
      "             nan             nan             nan             nan\n",
      " -28507.79031614 -28279.79619817 -28229.83743858 -28267.17932365\n",
      " -28433.88962223 -28312.8505256  -28319.41877166 -28314.45324878\n",
      "             nan             nan             nan             nan\n",
      " -29082.48392777 -28966.34098789 -28979.5348245  -28960.05934294\n",
      " -29030.10670956 -29020.80057378 -28980.90600493 -29010.53883618\n",
      "             nan             nan             nan             nan\n",
      " -28104.32603065 -28020.77318818 -28026.40464684 -27972.4207262\n",
      " -28240.80361045 -28108.08901556 -28155.46440415 -28086.83610118\n",
      "             nan             nan             nan             nan\n",
      " -28361.74602174 -28276.27791069 -28263.70027795 -28256.70867056\n",
      " -28506.652547   -28260.44573203 -28306.98736395 -28274.71707056\n",
      "             nan             nan             nan             nan\n",
      " -28968.03443135 -29050.49721077 -29014.17574944 -28970.88206276\n",
      " -29064.58814838 -29003.89864651 -28951.92126765 -28966.44637616\n",
      "             nan             nan             nan             nan\n",
      " -28086.30992317 -28074.39491709 -28015.90390644 -27978.02820706\n",
      " -28333.14282263 -28080.04830997 -28120.15214001 -28105.82200353\n",
      "             nan             nan             nan             nan\n",
      " -28499.88367633 -28262.12532493 -28226.51103763 -28225.43159561\n",
      " -28371.10426363 -28305.1315616  -28291.25835274 -28329.01062818\n",
      "             nan             nan             nan             nan\n",
      " -29064.44774113 -28997.73819294 -28971.55642004 -28960.26270587\n",
      " -29046.69167223 -29022.24234107 -29023.64117617 -28984.98136603\n",
      "             nan             nan             nan             nan\n",
      " -28084.5045235  -27947.71833624 -28000.62072439 -27955.61074306\n",
      " -28211.96132436 -28194.88271612 -28102.05303343 -28086.22402641\n",
      "             nan             nan             nan             nan\n",
      " -28421.86041813 -28229.67499861 -28253.61593563 -28242.73685029\n",
      " -28461.4274613  -28302.6683413  -28325.3127078  -28254.07994478\n",
      "             nan             nan             nan             nan\n",
      " -29113.91477402 -29006.81137838 -28960.80636132 -28966.50104007\n",
      " -29005.49812933 -29013.56332837 -28999.0216489  -28968.48104093\n",
      "             nan             nan             nan             nan\n",
      " -28155.67552368 -28034.40702419 -27984.71254546 -27999.87619876\n",
      " -28270.32561232 -28140.13129985 -28092.83051833 -28076.92102854\n",
      "             nan             nan             nan             nan\n",
      " -28458.32349255 -28239.22205265 -28273.42023953 -28204.03190529\n",
      " -28471.3068178  -28345.15092658 -28298.94692369 -28291.32945034\n",
      "             nan             nan             nan             nan\n",
      " -29117.40464109 -28979.56103296 -28958.08517474 -28959.6620871\n",
      " -29123.99386403 -29027.78181302 -28978.35023356 -28980.71714344]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 90, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 600}\n",
      "-27947.718336239923\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "params = None\n",
    "if METHOD_MODEL == \"xgb\":\n",
    "    model = XGBRegressor()\n",
    "    params = XGBOOST_PARAMS\n",
    "elif METHOD_MODEL == \"rf\":\n",
    "    model = RandomForestRegressor()\n",
    "    params = RANDOM_FOREST_PARAMS\n",
    "elif METHOD_MODEL == \"svc\":\n",
    "    model = SVC()\n",
    "    params = SVC_PARAMS\n",
    "elif METHOD_MODEL == 'xgbrf':\n",
    "    model = XGBRFRegressor()\n",
    "    params = XGBOOST_PARAMS\n",
    "else:\n",
    "    raise(\"Invalid model\")\n",
    "\n",
    "if LOG:\n",
    "    try:\n",
    "        log_file.write(\"Model: \" + METHOD_MODEL + \"\\n\")\n",
    "        log_file.write(\"Validation: \" + METHOD_VALIDATION + \"\\n\")\n",
    "        log_file.write(\"Search: \" + METHOD_SEARCH + \"\\n\")\n",
    "        log_file.write(\"Parameters: \" + str(params) + \"\\n\")\n",
    "    except IOError:\n",
    "        print(\"logger is not working\")\n",
    "\n",
    "if METHOD_VALIDATION == \"kf\" or METHOD_VALIDATION == \"skf\":\n",
    "    if METHOD_VALIDATION == \"kf\":\n",
    "        valid = kf\n",
    "    elif METHOD_VALIDATION == \"skf\":\n",
    "        valid = skf\n",
    "\n",
    "    if METHOD_SEARCH == \"grid\":\n",
    "        grid = GridSearchCVProgressBar(estimator=model, param_grid=params, cv=valid, n_jobs=-1, verbose=10, scoring=\"neg_mean_squared_error\")\n",
    "    elif METHOD_SEARCH == \"random\":\n",
    "        grid = RandomizedSearchCV(estimator=model, param_distributions=params, cv=valid, n_jobs=-1, verbose=10, scoring=\"neg_mean_squared_error\")\n",
    "    else:\n",
    "        raise(\"Invalid method for search\")\n",
    "    grid.fit(X_selected, y)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    if LOG:\n",
    "        try:\n",
    "            log_file.write(\"Best parameters: \" + str(grid.best_params_) + \"\\n\")\n",
    "            log_file.write(\"Best score: \" + str(grid.best_score_) + \"\\n\")\n",
    "        except IOError:\n",
    "            print(\"logger is not working\")\n",
    "\n",
    "elif METHOD_VALIDATION == None:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    # MSE\n",
    "    print(np.sqrt(np.mean((y_pred - y_val) ** 2)))\n",
    "    if LOG:\n",
    "        try:\n",
    "            log_file.write(\"MSE: \" + str(np.sqrt(np.mean((y_pred - y_val) ** 2))) + \"\\n\")\n",
    "        except IOError:\n",
    "            print(\"logger is not working\")\n",
    "else:\n",
    "    raise(\"Invalid method for validation\")\n",
    "\n",
    "best_model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID          MIN\n",
      "0        1    41.003333\n",
      "1        2  2337.045000\n",
      "2        3  1639.430000\n",
      "3        4   449.336667\n",
      "4        5   128.243333\n",
      "...    ...          ...\n",
      "1995  1996  2325.170000\n",
      "1996  1997  1072.152083\n",
      "1997  1998   992.110000\n",
      "1998  1999  1103.088333\n",
      "1999  2000   382.256667\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "model = best_model\n",
    "# y_pred = model.predict(testing_data_selected)\n",
    "y_pred = model.predict(testing_data)\n",
    "submission_df = pd.DataFrame()\n",
    "temp = pd.read_csv(DATA_PATH + \"\\\\test.csv\")\n",
    "submission_df[\"ID\"] = temp[\"ID\"]\n",
    "submission_df[\"MIN\"] = y_pred\n",
    "print(submission_df)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Close log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    log_file.close()\n",
    "except IOError:\n",
    "    print(\"logger is not working\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
