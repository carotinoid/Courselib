{"cells":[{"cell_type":"markdown","metadata":{"id":"6qG4I_JYrzGs"},"source":["# HW01\n","Welcome to the `assignment 1` of Introduction to Data Analysis.\n","\n","In this assignment, you will practice basics of python, numpy and pandas.\n","\n","Please follow the instructions below:\n","\n","1. Write down your code between <br>\n","&nbsp;&nbsp;&nbsp;&nbsp; **\\# BEGIN_YOUR_CODE**<br>\n","&nbsp;&nbsp;&nbsp;&nbsp; and<br>\n","&nbsp;&nbsp;&nbsp;&nbsp; **\\# END_YOUR_CODE**.\n","\n","2. Do not use **external libraries**. (i.e., Do not use any `import` in your code) <br>\n","   Your code will fail to execute and get **0 score** if you use them.\n","\n","3. Rename this file to **[student_id].ipynb** (e.g. 20230000.ipynb) and submit it to PLMS. <br>\n","   There is **30% penalty** if you do not follow the submission format.\n","\n","4. Submission late is not accepted.\n","   You will get **No score** for late submission."]},{"cell_type":"code","execution_count":103,"metadata":{"executionInfo":{"elapsed":508,"status":"ok","timestamp":1726118644573,"user":{"displayName":"JaeHwan Kim","userId":"11670003064547066089"},"user_tz":-540},"id":"6FRVCdh4rzGx"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"20KE9vQwrzG0"},"source":["## Problem 1. Factorial [2 points]\n","Given `n`, implement function `factorial(n)` that calculates `n!`. <br>\n","Assume `n` is zero or a positive integer. Just so you know, `0!` is defined as `1`.<br>\n"]},{"cell_type":"code","execution_count":104,"metadata":{"executionInfo":{"elapsed":584,"status":"ok","timestamp":1726118684530,"user":{"displayName":"JaeHwan Kim","userId":"11670003064547066089"},"user_tz":-540},"id":"V8SaGWRlrzG0"},"outputs":[],"source":["def factorial(n):\n","    # BEGIN_YOUR_CODE\n","    if n in (0, 1):\n","      return 1\n","    return n * factorial(n-1)\n","    # END_YOUR_CODE"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","2\n","6\n","24\n","120\n","720\n","5040\n","40320\n","362880\n"]}],"source":["# example\n","for i in range(1, 10):\n","    print(factorial(i))\n","    \n","# expected:\n","# 1\n","# 2\n","# 6\n","# 24\n","# 120\n","# 720\n","# 5040\n","# 40320\n","# 362880"]},{"cell_type":"markdown","metadata":{"id":"F1ugJ3Tw0G4Z"},"source":["### Explaination\n","\n","If `n` is 0 or 1, `facorial(n)` is 0. \\\\\n","If `n` is bigger than 1, `facorial(n)` returns `n` * `factorial(n-1)`.\n","\n","For example, the process of calculating `factorial(5)` is:\n","\n","`factorial(5)` \n","\n","= 5 $\\times$ `factorial(4)` \n","\n","= 5 $\\times$ 4 $\\times$ `factorial(3)` \n","\n","= 5 $\\times$ 4 $\\times$ 3 $\\times$ `factorial(2)` \n","\n","= 5 $\\times$ 4 $\\times$ 3 $\\times$ 2 $\\times$ `factorial(1)` \n","\n","= 5 $\\times$ 4 $\\times$ 3 $\\times$ 2 $\\times$ 1 = 120\n"]},{"cell_type":"markdown","metadata":{"id":"jI7VAPpPrzG1"},"source":["## Problem 2. Frequent Word Count [2 points]\n","Implement a function `freq_word_count(filename)` that takes a filename as input. <br>\n","This function should open the specified file and determine which words appear most frequently. It should return a `tuple` where the first item is the most frequent word and the second is the count of that word.<br>\n","If there are multiple words with the same maximum frequency, you can return any one of them.\n"]},{"cell_type":"code","execution_count":106,"metadata":{"executionInfo":{"elapsed":473,"status":"ok","timestamp":1726119718120,"user":{"displayName":"JaeHwan Kim","userId":"11670003064547066089"},"user_tz":-540},"id":"t-8yyYKKrzG1"},"outputs":[],"source":["def freq_word_count(filename):\n","    '''\n","    filename: .txt file\n","    '''\n","    # BEGIN_YOUR_CODE\n","    f = open(filename)\n","    lines = f.readlines()\n","    word_list = dict()\n","    for line in lines:\n","        words = line.split()\n","        for word in words:\n","            word.strip()\n","            if word in word_list:\n","                word_list[word] = word_list[word] + 1\n","            else:\n","                word_list[word] = 1\n","    max_word = 0\n","    count = 0\n","    for word in word_list:\n","        if(word_list[word] > count):\n","            max_word = word\n","            count = word_list[word]\n","    return (max_word, count)\n","    # END_YOUR_CODE"]},{"cell_type":"code","execution_count":120,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["('a', 3)\n"]}],"source":["# example\n","# --- test.txt\n","# a b c d\n","# a\n","# a\n","# cdcd\n","# --- EoF\n","filename = 'test.txt'\n","f = open(filename, 'w')\n","f.write(\"a b c d\\na\\na\\ncdcd\")\n","f.close()\n","print(freq_word_count(filename))\n","\n","# expected: \n","# ('a', 3)"]},{"cell_type":"markdown","metadata":{"id":"lkbGwzl-10RU"},"source":["### Explaination\n","\n","`f` reads the file named as `filename`, then each lines are stored in `lines` in the form of tuple. `word_list` is a dictionary with key and value, and its key is word, and value is the number of each word. This function counts all words from `lines`, records in the `word_list`, then it choosees the most frequently occured word in `word_list`.\n","\n","This function words as followes:\n","\n","let file is \"a b c d `\\n` a `\\n` a `\\n` cdcd\" where `\\n` is newline. \n","\n","Then lines is `[\"a b c d \\n\", \"a \\n\", \"a \\n\", \"cdcd\"]`. \n","\n","word is `a`, `b`, `c`, `d`, `a`, `a`, `cdcd`. \n","\n","\n","So, the most frequent word is `a`, 3 times."]},{"cell_type":"markdown","metadata":{"id":"YtsGoeR8rzG1"},"source":["## Problem 3. Median Score [3 points]\n","Given `students`, implement function `median_score(students)` that returns a dictionary with each student_id as a key and the median score as the value.<br> If the number of scores for a student is odd, the median is the middle score. If the number of scores is even, the median is the average of the two middle scores."]},{"cell_type":"code","execution_count":108,"metadata":{"executionInfo":{"elapsed":473,"status":"ok","timestamp":1726121785091,"user":{"displayName":"JaeHwan Kim","userId":"11670003064547066089"},"user_tz":-540},"id":"8ptm8InDrzG2"},"outputs":[],"source":["class Student:\n","    def __init__(self, args):\n","        name, student_id, grade =  args\n","        self.name = name\n","        self.student_id = student_id\n","        self.grade = grade\n","\n","def median_score(students):\n","    '''\n","    Args:\n","    students (dict): list of Student instances\n","\n","    Returns:\n","    result (dict): A dictionary where each key is a student_id and the value is the median score.\n","    '''\n","    # BEGIN_YOUR_CODE\n","    students = sorted(students, key = lambda Student: Student.grade)\n","    median = 0\n","    median_name = \"\"\n","    length_of_list = len(students)\n","    if(length_of_list % 2 == 0):\n","        median_name = students[length_of_list // 2 - 1].name\n","        median = (students[length_of_list // 2 - 1].grade + students[length_of_list // 2].grade) / 2\n","    else:\n","        median_name = students[length_of_list // 2].name\n","        median = students[length_of_list // 2].grade\n","    result = {median_name: median}\n","    # END_YOUR_CODE\n","    return result"]},{"cell_type":"code","execution_count":109,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1726120704166,"user":{"displayName":"JaeHwan Kim","userId":"11670003064547066089"},"user_tz":-540},"id":"hPpwz5cGysbY","outputId":"805c56aa-8d00-4bba-e1c9-d6628dbe5063"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'LEE': 20}\n","{'PARK': 17.5}\n"]}],"source":["# example\n","# When the number of students is odd.\n","t1 = [Student([\"KIM\", 20230001, 10]), Student([\"HUH\", 20230002, 30]), Student([\"LEE\", 20230003, 20])]\n","print(median_score(t1))\n","# expected: {'LEE': 20}\n","\n","#When the number of students is even.\n","t2 = [Student([\"KIM\", 20230001, 10]), Student([\"HUH\", 20230002, 30]), Student([\"LEE\", 20230003, 20]), Student([\"PARK\", 20230004, 15])]\n","print(median_score(t2))\n","# expected: {'PARK': 17.5}"]},{"cell_type":"markdown","metadata":{},"source":["## Explanation\n","\n","The argument is a list of `Student` instances. To get the median value, the function does as:\n","\n","1. Sort the elements of the list with key is grade (ascending order)\n","\n","2. the return, dictionary, is determined as:\n","\n","2-1. If the number of elements is odd, student's name which is placed in middle one and the value is his(her) grading.\n","\n","2-2. If the number of elements is even, the key is the student to the left of the center two students, and the value is the arithmetic mean of the center two students.\n"]},{"cell_type":"markdown","metadata":{"id":"1i7ellEzrzG2"},"source":["## Problem 4. Vector Norm [2 points]\n","Given two numpy arrays arr1 and arr2, and an integer n, implement a function `vector_norm` that calculates the n-th vector norm of the difference between arr1 and arr2. <br>\n","You need to utilize the numpy library for this problem."]},{"cell_type":"code","execution_count":110,"metadata":{"id":"yIKUM_narzG2"},"outputs":[],"source":["def vector_norm(arr1, arr2, n):\n","    # BEGIN_YOUR_CODE\n","    arr = arr1 - arr2\n","    norm = 0\n","    for elem in arr:\n","        norm += (elem ** 2)\n","    return norm**(1/2)\n","    # END_YOUR_CODE"]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["arr:  [-3  1 -3 -4]\n","5.916079783099616\n"]}],"source":["# example\n","a1 = np.array([1, 2, 3, 4])\n","a2 = np.array([4, 1, 6, 8])\n","print(\"arr: \", a1 - a2)\n","print(vector_norm(a1, a2, 4))\n","\n","# expected:\n","# arr:  [-3  1 -3 -4]\n","# 5.916079783099616"]},{"cell_type":"markdown","metadata":{},"source":["## Explanation\n","\n","The norm of N-vector $\\vec v$ is defined as:\n","$$\\|v\\| = \\sqrt{\\sum_i^N v_i^2} = \\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2}$$\n","\n","The difference of two vector can be calculated element-wisely.\n","\n","For example, $(1, 2, 3, 4)^T - (4, 1, 6, 8)^T = (1-4, 2-1, 3-6, 4-8)^T = (-3, 1, -3, 4)^T$\n","\n","Note\n","* The order of subtraction does not affect the result of the norm of a vector."]},{"cell_type":"markdown","metadata":{"id":"CQ06xWKmrzG3"},"source":["## Problem 5. CSV Modification [5 points]\n","Your goal is to modify given csv file with below constraints. <br>\n","The inputs are paths of the original data and modified data. <br>\n","You need to utilize pandas library for this problem.\n","\n","### Constraints\n","- The requirements must be followed in the same order as given below.<br>\n","  (If not, you might attain different results although you followed everything correctly.)\n","1. The modified csv file should contain rows where \"Active\" cases are greater than 10,000.\n","2. The modified csv file should only have `Europe` region.\n","3. Add new columns called \"Mortality_Rate\" and \"Recovery_Rate\", which are calculated as `(Deaths / Confirmed) * 100`, `(Recovered / Confirmed) * 100`.\n","4. Sort the data by \"Mortality Rate (%)\" in descending order\n"]},{"cell_type":"code","execution_count":112,"metadata":{"id":"4mpkZ5YdrzG3"},"outputs":[],"source":["import pandas as pd\n","\n","\n","def covid(original_file, modified_file):\n","    df = pd.read_csv(original_file)\n","    # BEGIN_YOUR_CODE\n","    df = df[df['Active'] > 10000]\n","    df = df[df[\"WHO Region\"] == \"Europe\"]\n","    df[\"Mortality_Rate\"] = (df[\"Deaths\"] / df[\"Confirmed\"]) * 100\n","    df[\"Recovery_Rate\"] = (df[\"Recovered\"] / df[\"Confirmed\"]) * 100\n","    df = df.sort_values(\"Mortality_Rate\", ascending = False)\n","    # END_YOUR_CODE\n","    df.to_csv(modified_file, index=False)\n","    return df"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Country/Region</th>\n","      <th>Confirmed</th>\n","      <th>Deaths</th>\n","      <th>Recovered</th>\n","      <th>Active</th>\n","      <th>New cases</th>\n","      <th>New deaths</th>\n","      <th>New recovered</th>\n","      <th>Deaths / 100 Recovered</th>\n","      <th>Confirmed last week</th>\n","      <th>1 week change</th>\n","      <th>1 week % increase</th>\n","      <th>WHO Region</th>\n","      <th>Mortality_Rate</th>\n","      <th>Recovery_Rate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>177</th>\n","      <td>United Kingdom</td>\n","      <td>301708</td>\n","      <td>45844</td>\n","      <td>1437</td>\n","      <td>254427</td>\n","      <td>688</td>\n","      <td>7</td>\n","      <td>3</td>\n","      <td>3190.26</td>\n","      <td>296944</td>\n","      <td>4764</td>\n","      <td>1.60</td>\n","      <td>Europe</td>\n","      <td>15.194824</td>\n","      <td>0.476288</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Belgium</td>\n","      <td>66428</td>\n","      <td>9822</td>\n","      <td>17452</td>\n","      <td>39154</td>\n","      <td>402</td>\n","      <td>1</td>\n","      <td>14</td>\n","      <td>56.28</td>\n","      <td>64094</td>\n","      <td>2334</td>\n","      <td>3.64</td>\n","      <td>Europe</td>\n","      <td>14.785934</td>\n","      <td>26.272054</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>Italy</td>\n","      <td>246286</td>\n","      <td>35112</td>\n","      <td>198593</td>\n","      <td>12581</td>\n","      <td>168</td>\n","      <td>5</td>\n","      <td>147</td>\n","      <td>17.68</td>\n","      <td>244624</td>\n","      <td>1662</td>\n","      <td>0.68</td>\n","      <td>Europe</td>\n","      <td>14.256596</td>\n","      <td>80.635115</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>France</td>\n","      <td>220352</td>\n","      <td>30212</td>\n","      <td>81212</td>\n","      <td>108928</td>\n","      <td>2551</td>\n","      <td>17</td>\n","      <td>267</td>\n","      <td>37.20</td>\n","      <td>214023</td>\n","      <td>6329</td>\n","      <td>2.96</td>\n","      <td>Europe</td>\n","      <td>13.710790</td>\n","      <td>36.855577</td>\n","    </tr>\n","    <tr>\n","      <th>120</th>\n","      <td>Netherlands</td>\n","      <td>53413</td>\n","      <td>6160</td>\n","      <td>189</td>\n","      <td>47064</td>\n","      <td>419</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3259.26</td>\n","      <td>52132</td>\n","      <td>1281</td>\n","      <td>2.46</td>\n","      <td>Europe</td>\n","      <td>11.532773</td>\n","      <td>0.353846</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>Spain</td>\n","      <td>272421</td>\n","      <td>28432</td>\n","      <td>150376</td>\n","      <td>93613</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>18.91</td>\n","      <td>264836</td>\n","      <td>7585</td>\n","      <td>2.86</td>\n","      <td>Europe</td>\n","      <td>10.436787</td>\n","      <td>55.199856</td>\n","    </tr>\n","    <tr>\n","      <th>161</th>\n","      <td>Sweden</td>\n","      <td>79395</td>\n","      <td>5700</td>\n","      <td>0</td>\n","      <td>73695</td>\n","      <td>398</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>inf</td>\n","      <td>78048</td>\n","      <td>1347</td>\n","      <td>1.73</td>\n","      <td>Europe</td>\n","      <td>7.179293</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>137</th>\n","      <td>Romania</td>\n","      <td>45902</td>\n","      <td>2206</td>\n","      <td>25794</td>\n","      <td>17902</td>\n","      <td>1104</td>\n","      <td>19</td>\n","      <td>151</td>\n","      <td>8.55</td>\n","      <td>38139</td>\n","      <td>7763</td>\n","      <td>20.35</td>\n","      <td>Europe</td>\n","      <td>4.805891</td>\n","      <td>56.193630</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>Kyrgyzstan</td>\n","      <td>33296</td>\n","      <td>1301</td>\n","      <td>21205</td>\n","      <td>10790</td>\n","      <td>483</td>\n","      <td>24</td>\n","      <td>817</td>\n","      <td>6.14</td>\n","      <td>27143</td>\n","      <td>6153</td>\n","      <td>22.67</td>\n","      <td>Europe</td>\n","      <td>3.907376</td>\n","      <td>63.686329</td>\n","    </tr>\n","    <tr>\n","      <th>135</th>\n","      <td>Portugal</td>\n","      <td>50299</td>\n","      <td>1719</td>\n","      <td>35375</td>\n","      <td>13205</td>\n","      <td>135</td>\n","      <td>2</td>\n","      <td>158</td>\n","      <td>4.86</td>\n","      <td>48771</td>\n","      <td>1528</td>\n","      <td>3.13</td>\n","      <td>Europe</td>\n","      <td>3.417563</td>\n","      <td>70.329430</td>\n","    </tr>\n","    <tr>\n","      <th>172</th>\n","      <td>Turkey</td>\n","      <td>227019</td>\n","      <td>5630</td>\n","      <td>210469</td>\n","      <td>10920</td>\n","      <td>919</td>\n","      <td>17</td>\n","      <td>982</td>\n","      <td>2.67</td>\n","      <td>220572</td>\n","      <td>6447</td>\n","      <td>2.92</td>\n","      <td>Europe</td>\n","      <td>2.479969</td>\n","      <td>92.709861</td>\n","    </tr>\n","    <tr>\n","      <th>175</th>\n","      <td>Ukraine</td>\n","      <td>67096</td>\n","      <td>1636</td>\n","      <td>37202</td>\n","      <td>28258</td>\n","      <td>835</td>\n","      <td>11</td>\n","      <td>317</td>\n","      <td>4.40</td>\n","      <td>60767</td>\n","      <td>6329</td>\n","      <td>10.42</td>\n","      <td>Europe</td>\n","      <td>2.438297</td>\n","      <td>55.445928</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>Serbia</td>\n","      <td>24141</td>\n","      <td>543</td>\n","      <td>0</td>\n","      <td>23598</td>\n","      <td>411</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>inf</td>\n","      <td>21253</td>\n","      <td>2888</td>\n","      <td>13.59</td>\n","      <td>Europe</td>\n","      <td>2.249285</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Armenia</td>\n","      <td>37390</td>\n","      <td>711</td>\n","      <td>26665</td>\n","      <td>10014</td>\n","      <td>73</td>\n","      <td>6</td>\n","      <td>187</td>\n","      <td>2.67</td>\n","      <td>34981</td>\n","      <td>2409</td>\n","      <td>6.89</td>\n","      <td>Europe</td>\n","      <td>1.901578</td>\n","      <td>71.315860</td>\n","    </tr>\n","    <tr>\n","      <th>138</th>\n","      <td>Russia</td>\n","      <td>816680</td>\n","      <td>13334</td>\n","      <td>602249</td>\n","      <td>201097</td>\n","      <td>5607</td>\n","      <td>85</td>\n","      <td>3077</td>\n","      <td>2.21</td>\n","      <td>776212</td>\n","      <td>40468</td>\n","      <td>5.21</td>\n","      <td>Europe</td>\n","      <td>1.632708</td>\n","      <td>73.743572</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>Israel</td>\n","      <td>63985</td>\n","      <td>474</td>\n","      <td>27133</td>\n","      <td>36378</td>\n","      <td>2029</td>\n","      <td>4</td>\n","      <td>108</td>\n","      <td>1.75</td>\n","      <td>52003</td>\n","      <td>11982</td>\n","      <td>23.04</td>\n","      <td>Europe</td>\n","      <td>0.740799</td>\n","      <td>42.405251</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>Kazakhstan</td>\n","      <td>84648</td>\n","      <td>585</td>\n","      <td>54404</td>\n","      <td>29659</td>\n","      <td>1526</td>\n","      <td>0</td>\n","      <td>1833</td>\n","      <td>1.08</td>\n","      <td>73468</td>\n","      <td>11180</td>\n","      <td>15.22</td>\n","      <td>Europe</td>\n","      <td>0.691097</td>\n","      <td>64.270863</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Country/Region  Confirmed  Deaths  Recovered  Active  New cases  \\\n","177  United Kingdom     301708   45844       1437  254427        688   \n","16          Belgium      66428    9822      17452   39154        402   \n","85            Italy     246286   35112     198593   12581        168   \n","61           France     220352   30212      81212  108928       2551   \n","120     Netherlands      53413    6160        189   47064        419   \n","157           Spain     272421   28432     150376   93613          0   \n","161          Sweden      79395    5700          0   73695        398   \n","137         Romania      45902    2206      25794   17902       1104   \n","93       Kyrgyzstan      33296    1301      21205   10790        483   \n","135        Portugal      50299    1719      35375   13205        135   \n","172          Turkey     227019    5630     210469   10920        919   \n","175         Ukraine      67096    1636      37202   28258        835   \n","147          Serbia      24141     543          0   23598        411   \n","7           Armenia      37390     711      26665   10014         73   \n","138          Russia     816680   13334     602249  201097       5607   \n","84           Israel      63985     474      27133   36378       2029   \n","89       Kazakhstan      84648     585      54404   29659       1526   \n","\n","     New deaths  New recovered  Deaths / 100 Recovered  Confirmed last week  \\\n","177           7              3                 3190.26               296944   \n","16            1             14                   56.28                64094   \n","85            5            147                   17.68               244624   \n","61           17            267                   37.20               214023   \n","120           1              0                 3259.26                52132   \n","157           0              0                   18.91               264836   \n","161           3              0                     inf                78048   \n","137          19            151                    8.55                38139   \n","93           24            817                    6.14                27143   \n","135           2            158                    4.86                48771   \n","172          17            982                    2.67               220572   \n","175          11            317                    4.40                60767   \n","147           9              0                     inf                21253   \n","7             6            187                    2.67                34981   \n","138          85           3077                    2.21               776212   \n","84            4            108                    1.75                52003   \n","89            0           1833                    1.08                73468   \n","\n","     1 week change  1 week % increase WHO Region  Mortality_Rate  \\\n","177           4764               1.60     Europe       15.194824   \n","16            2334               3.64     Europe       14.785934   \n","85            1662               0.68     Europe       14.256596   \n","61            6329               2.96     Europe       13.710790   \n","120           1281               2.46     Europe       11.532773   \n","157           7585               2.86     Europe       10.436787   \n","161           1347               1.73     Europe        7.179293   \n","137           7763              20.35     Europe        4.805891   \n","93            6153              22.67     Europe        3.907376   \n","135           1528               3.13     Europe        3.417563   \n","172           6447               2.92     Europe        2.479969   \n","175           6329              10.42     Europe        2.438297   \n","147           2888              13.59     Europe        2.249285   \n","7             2409               6.89     Europe        1.901578   \n","138          40468               5.21     Europe        1.632708   \n","84           11982              23.04     Europe        0.740799   \n","89           11180              15.22     Europe        0.691097   \n","\n","     Recovery_Rate  \n","177       0.476288  \n","16       26.272054  \n","85       80.635115  \n","61       36.855577  \n","120       0.353846  \n","157      55.199856  \n","161       0.000000  \n","137      56.193630  \n","93       63.686329  \n","135      70.329430  \n","172      92.709861  \n","175      55.445928  \n","147       0.000000  \n","7        71.315860  \n","138      73.743572  \n","84       42.405251  \n","89       64.270863  "]},"execution_count":113,"metadata":{},"output_type":"execute_result"}],"source":["# example\n","# The csv file is placed in root workspace folder   \n","covid(\"COVID.csv\", \"COVID_revised.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Explanation\n","Each lines does as:\n","1. Select the columns which `Active` is bigger than 10000\n","2. Select the columns which `WHO Region` is Europe\n","3. Add Mortality_Rate\n","4. Add Recovery_Rate\n","5. Sort in descending order based on Mortality_rate."]},{"cell_type":"markdown","metadata":{"id":"rYPZXbSorzG3"},"source":["## Problem 6. Employee and Department [6 points]\n","For this problem, three csv files, `departments.csv`, `employees.csv` and `employees2.csv`, are given. <br>\n","There are 2 sub problems. <br>\n","You need to utilize pandas library for this problem."]},{"cell_type":"markdown","metadata":{"id":"5iq_VB7JrzG3"},"source":["### 6.a Employee Table [3 points]\n","Make employee table that has `name`, `salary` and `department_name` as columns. <br>\n","Note that each department has its own `department_id` and `department_name`."]},{"cell_type":"code","execution_count":114,"metadata":{"id":"CWXQpTsHrzG3"},"outputs":[],"source":["def emp_table(dep, emp1, emp2):\n","    # BEGIN_YOUR_CODE\n","    ddf = pd.read_csv(dep)\n","    edf1 = pd.read_csv(emp1)\n","    edf2 = pd.read_csv(emp2)\n","    df = pd.concat([edf1, edf2])\n","    df = pd.merge(df, ddf, on = 'department_id', how = 'inner')\n","    df = df[['name', 'salary', 'department_name']]\n","    # END_YOUR_CODE\n","    return df"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>salary</th>\n","      <th>department_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>John</td>\n","      <td>5000</td>\n","      <td>sales</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Allen</td>\n","      <td>6000</td>\n","      <td>accounting</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Martin</td>\n","      <td>3500</td>\n","      <td>research</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Mary</td>\n","      <td>5500</td>\n","      <td>sales</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Smith</td>\n","      <td>4500</td>\n","      <td>research</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Scott</td>\n","      <td>7100</td>\n","      <td>accounting</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Tom</td>\n","      <td>4500</td>\n","      <td>sales</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Admas</td>\n","      <td>5000</td>\n","      <td>research</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Hunter</td>\n","      <td>3000</td>\n","      <td>research</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>King</td>\n","      <td>5100</td>\n","      <td>accounting</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     name  salary department_name\n","0    John    5000           sales\n","1   Allen    6000      accounting\n","2  Martin    3500        research\n","3    Mary    5500           sales\n","4   Smith    4500        research\n","5   Scott    7100      accounting\n","6     Tom    4500           sales\n","7   Admas    5000        research\n","8  Hunter    3000        research\n","9    King    5100      accounting"]},"execution_count":115,"metadata":{},"output_type":"execute_result"}],"source":["# example\n","emp_table(\"departments.csv\", \"employees.csv\", \"employees2.csv\")"]},{"cell_type":"markdown","metadata":{"id":"dTR7_jUcrzG3"},"source":["### 6.b Highest Average Salary [3 points]\n","Find the department that has the highest average salary.<br>\n","The output should be a dictionary with the `department_name` as the key and its highest average salary as the value. <br>\n","You can use the `emp_table` provided in 6.a."]},{"cell_type":"code","execution_count":116,"metadata":{"id":"CNTuE258rzG3"},"outputs":[],"source":["def highest_avg_salary(dep, emp1, emp2):\n","    # BEGIN_YOUR_CODE\n","    avg_salary = emp_table(dep, emp1, emp2).groupby('department_name')['salary'].mean() \n","    highest_avg_dept = avg_salary.idxmax()\n","    highest_avg_salary = avg_salary.max()\n","    result = dict()\n","    result[highest_avg_dept] = highest_avg_salary.item()\n","    return result\n","    # END_YOUR_CODE"]},{"cell_type":"code","execution_count":117,"metadata":{},"outputs":[{"data":{"text/plain":["{'accounting': 6066.666666666667}"]},"execution_count":117,"metadata":{},"output_type":"execute_result"}],"source":["# example\n","highest_avg_salary(\"departments.csv\", \"employees.csv\", \"employees2.csv\")\n","\n","# expected:\n","# {'accounting': 6066.666666666667}"]},{"cell_type":"markdown","metadata":{},"source":["## Explanation\n","### 6.a\n","`emp_table()` function gets three arguments: the name of departments, employees, employees2 files.\n","\n","First, the function reads three csv files as pandas dataframe.\n","\n","Second, it connects two employee dataframe using `concat()`.\n","\n","Third, it does innerjoin from employee to departments using `merge()`\n","\n","Fourth, it selects columns `name`, `salary`, and `department_name`\n","\n","### 6.b\n","`highest_avg_salary()` function gets three arguments: the name of departments, employees, employees2 files.\n","\n","First, the function gets the average salary of each department using 6.a `emp_table()` and `groupby()`. The average salary dataframe is like as:\n","\n","department_name<br>\n","accounting    6066.666667<br>\n","research      4000.000000<br>\n","sales         5000.000000<br>\n","Name: salary, dtype: float64\n","\n","Second, it select the name and salary of department which has the most average salary using `idxmax()` and `max()`.\n","\n","Third, it returns the dictionary which it's key is department name and value is salary.\n","\n","Because the data type of average calculated with `groupby()` is `np.float32`, we have to use `.item()` to convert from `np.float32` to float."]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
